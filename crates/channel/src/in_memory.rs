// SPDX-License-Identifier: LGPL-2.1-or-later
// Copyright (C) 2025 Shahzad A. Bhatti <bhatti@plexobject.com>
//
// This file is part of PlexSpaces.
//
// PlexSpaces is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published by
// the Free Software Foundation, either version 2.1 of the License, or
// (at your option) any later version.
//
// PlexSpaces is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with PlexSpaces. If not, see <https://www.gnu.org/licenses/>.

//! InMemory channel implementation using Tokio MPSC channels

use crate::{Channel, ChannelError, ChannelResult};
use async_trait::async_trait;
use futures::stream::BoxStream;
use plexspaces_proto::channel::v1::{
    channel_config, ChannelBackend, ChannelConfig, ChannelMessage, ChannelStats, DeliveryGuarantee,
};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::{broadcast, mpsc, RwLock};
use tokio::time::timeout;

// Enum to handle both bounded and unbounded channel types
enum ChannelSender {
    Bounded(mpsc::Sender<ChannelMessage>),
    Unbounded(mpsc::UnboundedSender<ChannelMessage>),
}

enum ChannelReceiver {
    Bounded(mpsc::Receiver<ChannelMessage>),
    Unbounded(mpsc::UnboundedReceiver<ChannelMessage>),
}

impl ChannelSender {
    async fn send(
        &self,
        msg: ChannelMessage,
    ) -> Result<(), mpsc::error::SendError<ChannelMessage>> {
        match self {
            ChannelSender::Bounded(tx) => tx.send(msg).await,
            ChannelSender::Unbounded(tx) => tx.send(msg).map_err(|e| {
                // Convert UnboundedSendError to SendError
                mpsc::error::SendError(e.0)
            }),
        }
    }
}

impl ChannelReceiver {
    async fn recv(&mut self) -> Option<ChannelMessage> {
        match self {
            ChannelReceiver::Bounded(rx) => rx.recv().await,
            ChannelReceiver::Unbounded(rx) => rx.recv().await,
        }
    }

    fn try_recv(&mut self) -> Result<ChannelMessage, mpsc::error::TryRecvError> {
        match self {
            ChannelReceiver::Bounded(rx) => rx.try_recv(),
            ChannelReceiver::Unbounded(rx) => rx.try_recv(),
        }
    }
}

/// InMemory channel implementation using Tokio channels
///
/// ## Purpose
/// Provides Go-like MPSC (multi-producer, single-consumer) channels for
/// fast, same-node communication between actors.
///
/// ## Architecture Context
/// This is the primary channel implementation for:
/// - Elastic actor pools distributing work
/// - GenServer request queues
/// - Event buses within a node
///
/// ## Design Decisions
/// - **MPSC**: Multiple senders, single receiver (Go-like semantics)
/// - **Bounded/Unbounded**: Configurable capacity (0 = unbounded)
/// - **Backpressure**: Blocks senders when full (configurable strategy)
/// - **Non-Persistent**: Messages lost on restart (use Redis for durability)
///
/// ## Performance
/// - Latency: < 10Î¼s for send/receive
/// - Throughput: > 1M messages/second
/// - Memory: ~100 bytes per pending message
pub struct InMemoryChannel {
    config: ChannelConfig,
    sender: ChannelSender,
    receiver: Arc<RwLock<ChannelReceiver>>,
    broadcast_tx: broadcast::Sender<ChannelMessage>,
    stats: Arc<RwLock<ChannelStatsData>>,
    closed: Arc<RwLock<bool>>,
    pending_acks: Arc<RwLock<HashMap<String, ChannelMessage>>>,
}

#[derive(Default)]
struct ChannelStatsData {
    messages_sent: u64,
    messages_received: u64,
    messages_pending: u64,
    messages_failed: u64,
}

impl InMemoryChannel {
    /// Create a new in-memory channel
    ///
    /// ## Arguments
    /// * `config` - Channel configuration from proto
    ///
    /// ## Returns
    /// New InMemoryChannel instance
    ///
    /// ## Errors
    /// - [`ChannelError::InvalidConfiguration`]: Invalid capacity or backend
    ///
    /// ## Examples
    /// ```rust
    /// # use plexspaces_channel::*;
    /// # use plexspaces_proto::plexspaces::channel::v1::*;
    /// # async fn example() -> ChannelResult<()> {
    /// let config = ChannelConfig {
    ///     name: "work-queue".to_string(),
    ///     backend: ChannelBackend::ChannelBackendInMemory as i32,
    ///     capacity: 100,
    ///     delivery: DeliveryGuarantee::DeliveryGuaranteeAtLeastOnce as i32,
    ///     ordering: OrderingGuarantee::OrderingGuaranteeFifo as i32,
    ///     ..Default::default()
    /// };
    ///
    /// let channel = InMemoryChannel::new(config).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn new(config: ChannelConfig) -> ChannelResult<Self> {
        // Validate config
        if config.backend() != ChannelBackend::ChannelBackendInMemory {
            return Err(ChannelError::InvalidConfiguration(format!(
                "Invalid backend for InMemoryChannel: {:?}",
                config.backend()
            )));
        }

        // Create MPSC channel
        let (sender, receiver) = if config.capacity == 0 {
            // Unbounded channel
            let (tx, rx) = mpsc::unbounded_channel();
            (ChannelSender::Unbounded(tx), ChannelReceiver::Unbounded(rx))
        } else {
            // Bounded channel
            let (tx, rx) = mpsc::channel(config.capacity as usize);
            (ChannelSender::Bounded(tx), ChannelReceiver::Bounded(rx))
        };

        // Create broadcast channel for pub/sub
        let (broadcast_tx, _) = broadcast::channel(1024);

        Ok(Self {
            config,
            sender,
            receiver: Arc::new(RwLock::new(receiver)),
            broadcast_tx,
            stats: Arc::new(RwLock::new(ChannelStatsData::default())),
            closed: Arc::new(RwLock::new(false)),
            pending_acks: Arc::new(RwLock::new(HashMap::new())),
        })
    }

    /// Get timeout from config
    fn get_send_timeout(&self) -> Option<Duration> {
        self.config.backend_config.as_ref().and_then(|bc| match bc {
            channel_config::BackendConfig::InMemory(ref im_config) => {
                im_config.send_timeout.as_ref().map(|d| {
                    Duration::from_secs(d.seconds as u64) + Duration::from_nanos(d.nanos as u64)
                })
            }
            _ => None,
        })
    }

    fn get_receive_timeout(&self) -> Option<Duration> {
        self.config.backend_config.as_ref().and_then(|bc| match bc {
            channel_config::BackendConfig::InMemory(ref im_config) => {
                im_config.receive_timeout.as_ref().map(|d| {
                    Duration::from_secs(d.seconds as u64) + Duration::from_nanos(d.nanos as u64)
                })
            }
            _ => None,
        })
    }
}

#[async_trait]
impl Channel for InMemoryChannel {
    async fn send(&self, message: ChannelMessage) -> ChannelResult<String> {
        // Check if closed
        if *self.closed.read().await {
            return Err(ChannelError::ChannelClosed(self.config.name.clone()));
        }

        let msg_id = message.id.clone();

        // Send with timeout if configured
        if let Some(timeout_dur) = self.get_send_timeout() {
            match timeout(timeout_dur, self.sender.send(message)).await {
                Ok(Ok(_)) => {
                    let mut stats = self.stats.write().await;
                    stats.messages_sent += 1;
                    stats.messages_pending += 1;
                    Ok(msg_id)
                }
                Ok(Err(_)) => Err(ChannelError::ChannelClosed(self.config.name.clone())),
                Err(_) => Err(ChannelError::Timeout(format!(
                    "Send timeout after {:?}",
                    timeout_dur
                ))),
            }
        } else {
            // No timeout, send directly
            self.sender
                .send(message)
                .await
                .map_err(|_| ChannelError::ChannelClosed(self.config.name.clone()))?;

            let mut stats = self.stats.write().await;
            stats.messages_sent += 1;
            stats.messages_pending += 1;
            Ok(msg_id)
        }
    }

    async fn receive(&self, max_messages: u32) -> ChannelResult<Vec<ChannelMessage>> {
        let mut messages = Vec::new();
        let mut receiver = self.receiver.write().await;

        // Try to receive up to max_messages
        for _ in 0..max_messages {
            if let Some(timeout_dur) = self.get_receive_timeout() {
                match timeout(timeout_dur, receiver.recv()).await {
                    Ok(Some(msg)) => {
                        messages.push(msg);
                    }
                    Ok(None) => break, // Channel closed
                    Err(_) => {
                        if messages.is_empty() {
                            return Err(ChannelError::Timeout(format!(
                                "Receive timeout after {:?}",
                                timeout_dur
                            )));
                        }
                        break;
                    }
                }
            } else {
                // No timeout, block until message
                if let Some(msg) = receiver.recv().await {
                    messages.push(msg);
                } else {
                    break;
                }
            }

            // If we got at least one message and max_messages is 1, return early
            if max_messages == 1 && !messages.is_empty() {
                break;
            }
        }

        // Update stats
        let mut stats = self.stats.write().await;
        stats.messages_received += messages.len() as u64;
        stats.messages_pending = stats.messages_pending.saturating_sub(messages.len() as u64);

        // Store for potential ack/nack
        if self.config.delivery() == DeliveryGuarantee::DeliveryGuaranteeAtLeastOnce {
            let mut pending_acks = self.pending_acks.write().await;
            for msg in &messages {
                pending_acks.insert(msg.id.clone(), msg.clone());
            }
        }

        Ok(messages)
    }

    async fn try_receive(&self, max_messages: u32) -> ChannelResult<Vec<ChannelMessage>> {
        let mut messages = Vec::new();
        let mut receiver = self.receiver.write().await;

        // Try to receive without blocking
        for _ in 0..max_messages {
            match receiver.try_recv() {
                Ok(msg) => messages.push(msg),
                Err(mpsc::error::TryRecvError::Empty) => break,
                Err(mpsc::error::TryRecvError::Disconnected) => {
                    return Err(ChannelError::ChannelClosed(self.config.name.clone()));
                }
            }
        }

        // Update stats
        if !messages.is_empty() {
            let mut stats = self.stats.write().await;
            stats.messages_received += messages.len() as u64;
            stats.messages_pending = stats.messages_pending.saturating_sub(messages.len() as u64);

            // Store for potential ack/nack
            if self.config.delivery() == DeliveryGuarantee::DeliveryGuaranteeAtLeastOnce {
                let mut pending_acks = self.pending_acks.write().await;
                for msg in &messages {
                    pending_acks.insert(msg.id.clone(), msg.clone());
                }
            }
        }

        Ok(messages)
    }

    async fn subscribe(
        &self,
        _consumer_group: Option<String>,
    ) -> ChannelResult<BoxStream<'static, ChannelMessage>> {
        let mut rx = self.broadcast_tx.subscribe();

        let stream = async_stream::stream! {
            while let Ok(msg) = rx.recv().await {
                yield msg;
            }
        };

        Ok(Box::pin(stream))
    }

    async fn publish(&self, message: ChannelMessage) -> ChannelResult<u32> {
        // Check if closed
        if *self.closed.read().await {
            return Err(ChannelError::ChannelClosed(self.config.name.clone()));
        }

        // Broadcast to all subscribers
        let subscriber_count = self.broadcast_tx.receiver_count();
        let _ = self.broadcast_tx.send(message); // Ignore send errors (no subscribers)

        // Update stats
        let mut stats = self.stats.write().await;
        stats.messages_sent += 1;

        Ok(subscriber_count as u32)
    }

    async fn ack(&self, message_id: &str) -> ChannelResult<()> {
        // Remove from pending acks
        let mut pending_acks = self.pending_acks.write().await;
        if pending_acks.remove(message_id).is_some() {
            Ok(())
        } else {
            Err(ChannelError::MessageNotFound(message_id.to_string()))
        }
    }

    async fn nack(&self, message_id: &str, requeue: bool) -> ChannelResult<()> {
        let mut pending_acks = self.pending_acks.write().await;

        if let Some(msg) = pending_acks.remove(message_id) {
            if requeue {
                // Requeue the message
                drop(pending_acks); // Release lock before sending
                self.send(msg).await?;
            } else {
                // Send to DLQ if configured
                if !self.config.dead_letter_queue.is_empty() {
                    tracing::warn!(
                        "Message {} should go to DLQ {} (not implemented)",
                        message_id,
                        &self.config.dead_letter_queue
                    );
                    // TODO: Implement DLQ
                }
            }
            Ok(())
        } else {
            Err(ChannelError::MessageNotFound(message_id.to_string()))
        }
    }

    async fn get_stats(&self) -> ChannelResult<ChannelStats> {
        let stats = self.stats.read().await;

        Ok(ChannelStats {
            name: self.config.name.clone(),
            backend: self.config.backend,
            messages_sent: stats.messages_sent,
            messages_received: stats.messages_received,
            messages_pending: stats.messages_pending,
            messages_failed: stats.messages_failed,
            avg_latency_us: 0, // TODO: Track latency
            throughput: 0.0,   // TODO: Calculate throughput
            backend_stats: HashMap::new(),
        })
    }

    async fn close(&self) -> ChannelResult<()> {
        let mut closed = self.closed.write().await;
        *closed = true;
        Ok(())
    }

    fn is_closed(&self) -> bool {
        // Use try_read to avoid blocking
        self.closed.try_read().map(|c| *c).unwrap_or(false)
    }

    fn get_config(&self) -> &ChannelConfig {
        &self.config
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use futures::StreamExt;
    use plexspaces_proto::channel::v1::{
        in_memory_config, DeliveryGuarantee, InMemoryConfig, OrderingGuarantee,
    };
    use prost_types::Duration as ProtoDuration;

    fn create_test_config(capacity: u64) -> ChannelConfig {
        ChannelConfig {
            name: "test-channel".to_string(),
            backend: ChannelBackend::ChannelBackendInMemory as i32,
            capacity,
            delivery: DeliveryGuarantee::DeliveryGuaranteeAtLeastOnce as i32,
            ordering: OrderingGuarantee::OrderingGuaranteeFifo as i32,
            backend_config: Some(channel_config::BackendConfig::InMemory(InMemoryConfig {
                backpressure: in_memory_config::BackpressureStrategy::BackpressureStrategyBlock as i32,
                send_timeout: Some(ProtoDuration {
                    seconds: 1,
                    nanos: 0,
                }),
                receive_timeout: Some(ProtoDuration {
                    seconds: 1,
                    nanos: 0,
                }),
            })),
            ..Default::default()
        }
    }

    fn create_test_message(id: &str, payload: &str) -> ChannelMessage {
        ChannelMessage {
            id: id.to_string(),
            channel: "test-channel".to_string(),
            payload: payload.as_bytes().to_vec(),
            ..Default::default()
        }
    }

    #[tokio::test]
    async fn test_create_bounded_channel() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await;
        assert!(channel.is_ok());

        let channel = channel.unwrap();
        assert!(!channel.is_closed());
        assert_eq!(channel.get_config().capacity, 10);
    }

    #[tokio::test]
    async fn test_create_unbounded_channel() {
        let config = create_test_config(0);
        let channel = InMemoryChannel::new(config).await;
        assert!(channel.is_ok());

        let channel = channel.unwrap();
        assert_eq!(channel.get_config().capacity, 0);
    }

    #[tokio::test]
    async fn test_send_and_receive_single_message() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        let msg = create_test_message("msg1", "hello world");
        let msg_id = channel.send(msg.clone()).await.unwrap();
        assert_eq!(msg_id, "msg1");

        let received = channel.receive(1).await.unwrap();
        assert_eq!(received.len(), 1);
        assert_eq!(received[0].id, "msg1");
        assert_eq!(received[0].payload, b"hello world");
    }

    #[tokio::test]
    async fn test_send_and_receive_multiple_messages() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        // Send 5 messages
        for i in 0..5 {
            let msg = create_test_message(&format!("msg{}", i), &format!("payload {}", i));
            channel.send(msg).await.unwrap();
        }

        // Receive all 5 messages
        let received = channel.receive(5).await.unwrap();
        assert_eq!(received.len(), 5);

        // Verify FIFO ordering
        for (i, msg) in received.iter().enumerate() {
            assert_eq!(msg.id, format!("msg{}", i));
            assert_eq!(msg.payload, format!("payload {}", i).as_bytes());
        }
    }

    #[tokio::test]
    async fn test_try_receive_empty() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        let received = channel.try_receive(1).await.unwrap();
        assert_eq!(received.len(), 0);
    }

    #[tokio::test]
    async fn test_try_receive_with_messages() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        // Send 3 messages
        for i in 0..3 {
            let msg = create_test_message(&format!("msg{}", i), "data");
            channel.send(msg).await.unwrap();
        }

        // Try receive (non-blocking)
        let received = channel.try_receive(5).await.unwrap();
        assert_eq!(received.len(), 3);
    }

    #[tokio::test]
    async fn test_ack() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        let msg = create_test_message("msg1", "data");
        channel.send(msg).await.unwrap();

        let received = channel.receive(1).await.unwrap();
        assert_eq!(received.len(), 1);

        // Ack the message
        let result = channel.ack(&received[0].id).await;
        assert!(result.is_ok());

        // Acking again should fail
        let result = channel.ack(&received[0].id).await;
        assert!(matches!(result, Err(ChannelError::MessageNotFound(_))));
    }

    #[tokio::test]
    async fn test_nack_requeue() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        let msg = create_test_message("msg1", "data");
        channel.send(msg).await.unwrap();

        let received = channel.receive(1).await.unwrap();
        assert_eq!(received.len(), 1);

        // Nack with requeue
        channel.nack(&received[0].id, true).await.unwrap();

        // Should be able to receive again
        let received_again = channel.receive(1).await.unwrap();
        assert_eq!(received_again.len(), 1);
        assert_eq!(received_again[0].id, "msg1");
    }

    #[tokio::test]
    async fn test_publish_subscribe() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        // Subscribe first
        let mut stream = channel.subscribe(None).await.unwrap();

        // Publish message
        let msg = create_test_message("event1", "event data");
        let sub_count = channel.publish(msg).await.unwrap();
        assert_eq!(sub_count, 1); // One subscriber

        // Receive from subscription
        let received = tokio::time::timeout(Duration::from_secs(1), stream.next()).await;
        assert!(received.is_ok());

        let event = received.unwrap();
        assert!(event.is_some());
        assert_eq!(event.unwrap().id, "event1");
    }

    #[tokio::test]
    async fn test_close_channel() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        assert!(!channel.is_closed());

        channel.close().await.unwrap();
        assert!(channel.is_closed());

        // Sending to closed channel should fail
        let msg = create_test_message("msg1", "data");
        let result = channel.send(msg).await;
        assert!(matches!(result, Err(ChannelError::ChannelClosed(_))));
    }

    #[tokio::test]
    async fn test_get_stats() {
        let config = create_test_config(10);
        let channel = InMemoryChannel::new(config).await.unwrap();

        // Send 3 messages
        for i in 0..3 {
            let msg = create_test_message(&format!("msg{}", i), "data");
            channel.send(msg).await.unwrap();
        }

        // Receive 2 messages
        channel.receive(2).await.unwrap();

        let stats = channel.get_stats().await.unwrap();
        assert_eq!(stats.messages_sent, 3);
        assert_eq!(stats.messages_received, 2);
        assert_eq!(stats.messages_pending, 1);
    }
}
