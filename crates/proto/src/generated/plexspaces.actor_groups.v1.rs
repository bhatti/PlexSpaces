// @generated
// This file is @generated by prost-build.
/// Actor group - collection of sharded actors with the same behavior
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ActorGroup {
    /// Unique group identifier
    #[prost(string, tag="1")]
    pub group_id: ::prost::alloc::string::String,
    /// Actor type for all shards (must be the same)
    #[prost(string, tag="2")]
    pub actor_type: ::prost::alloc::string::String,
    /// Number of shards in this group
    #[prost(uint32, tag="3")]
    pub shard_count: u32,
    /// Partition strategy for routing messages
    #[prost(enumeration="super::super::actor::v1::PartitionStrategy", tag="4")]
    pub partition_strategy: i32,
    /// Actor IDs for each shard (indexed by shard_id)
    #[prost(string, repeated, tag="5")]
    pub shard_actors: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Current group state
    #[prost(enumeration="GroupState", tag="6")]
    pub state: i32,
    /// Rebalancing status (if currently rebalancing)
    #[prost(message, optional, tag="7")]
    pub rebalance_status: ::core::option::Option<RebalanceStatus>,
    /// When the group was created
    #[prost(message, optional, tag="8")]
    pub created_at: ::core::option::Option<::prost_types::Timestamp>,
    /// Group metadata
    #[prost(map="string, string", tag="9")]
    pub metadata: ::std::collections::HashMap<::prost::alloc::string::String, ::prost::alloc::string::String>,
}
// Partition strategy imported from actor_runtime.proto
// See plexspaces.actor.v1.PartitionStrategy

/// Rebalancing status
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RebalanceStatus {
    /// Is currently rebalancing
    #[prost(bool, tag="1")]
    pub is_rebalancing: bool,
    /// Old shard count (before rebalancing)
    #[prost(uint32, tag="2")]
    pub old_shard_count: u32,
    /// New shard count (after rebalancing)
    #[prost(uint32, tag="3")]
    pub new_shard_count: u32,
    /// Progress (0.0 to 100.0)
    #[prost(double, tag="4")]
    pub progress_percent: f64,
    /// When rebalancing started
    #[prost(message, optional, tag="5")]
    pub started_at: ::core::option::Option<::prost_types::Timestamp>,
    /// Estimated completion time
    #[prost(message, optional, tag="6")]
    pub estimated_completion: ::core::option::Option<::prost_types::Timestamp>,
}
/// Scatter-gather query across all shards in a group
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScatterGatherQuery {
    /// Group to query
    #[prost(string, tag="1")]
    pub group_id: ::prost::alloc::string::String,
    /// Query message to send to all shards
    #[prost(message, optional, tag="2")]
    pub query: ::core::option::Option<super::super::actor::v1::Message>,
    /// Timeout for gathering results
    #[prost(message, optional, tag="3")]
    pub timeout: ::core::option::Option<::prost_types::Duration>,
    /// Aggregation strategy for combining results
    #[prost(enumeration="AggregationStrategy", tag="4")]
    pub aggregation: i32,
    /// Minimum number of shards that must respond (default: all)
    #[prost(uint32, tag="5")]
    pub min_responses: u32,
}
/// Scatter-gather response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScatterGatherResponse {
    /// Aggregated result
    #[prost(message, optional, tag="1")]
    pub result: ::core::option::Option<super::super::actor::v1::Message>,
    /// Individual shard responses
    #[prost(message, repeated, tag="2")]
    pub shard_responses: ::prost::alloc::vec::Vec<ShardResponse>,
    /// Statistics
    #[prost(message, optional, tag="3")]
    pub stats: ::core::option::Option<ScatterGatherStats>,
}
/// Response from a single shard
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ShardResponse {
    /// Shard ID that responded
    #[prost(uint32, tag="1")]
    pub shard_id: u32,
    /// Response message
    #[prost(message, optional, tag="2")]
    pub response: ::core::option::Option<super::super::actor::v1::Message>,
    /// Response latency
    #[prost(message, optional, tag="3")]
    pub latency: ::core::option::Option<::prost_types::Duration>,
    /// Success flag
    #[prost(bool, tag="4")]
    pub success: bool,
    /// Error message (if failed)
    #[prost(string, tag="5")]
    pub error: ::prost::alloc::string::String,
}
/// Scatter-gather statistics
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScatterGatherStats {
    /// Total shards queried
    #[prost(uint32, tag="1")]
    pub shards_queried: u32,
    /// Shards that responded
    #[prost(uint32, tag="2")]
    pub shards_responded: u32,
    /// Maximum latency across all shards
    #[prost(message, optional, tag="3")]
    pub max_latency: ::core::option::Option<::prost_types::Duration>,
    /// Total time for scatter-gather operation
    #[prost(message, optional, tag="4")]
    pub total_time: ::core::option::Option<::prost_types::Duration>,
    /// Average latency
    #[prost(message, optional, tag="5")]
    pub avg_latency: ::core::option::Option<::prost_types::Duration>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CreateGroupRequest {
    /// Group identifier
    #[prost(string, tag="1")]
    pub group_id: ::prost::alloc::string::String,
    /// Actor type for all shards
    #[prost(string, tag="2")]
    pub actor_type: ::prost::alloc::string::String,
    /// Number of shards to create
    #[prost(uint32, tag="3")]
    pub shard_count: u32,
    /// Partition strategy
    #[prost(enumeration="super::super::actor::v1::PartitionStrategy", tag="4")]
    pub partition_strategy: i32,
    /// Configuration for each shard actor
    #[prost(message, optional, tag="5")]
    pub shard_config: ::core::option::Option<super::super::actor::v1::ActorConfig>,
    /// Initial state for each shard (if any)
    #[prost(bytes="vec", tag="6")]
    pub initial_state: ::prost::alloc::vec::Vec<u8>,
    /// Group metadata
    #[prost(map="string, string", tag="7")]
    pub metadata: ::std::collections::HashMap<::prost::alloc::string::String, ::prost::alloc::string::String>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CreateGroupResponse {
    /// Created actor group
    #[prost(message, optional, tag="1")]
    pub group: ::core::option::Option<ActorGroup>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DeleteGroupRequest {
    /// Group to delete
    #[prost(string, tag="1")]
    pub group_id: ::prost::alloc::string::String,
    /// Force deletion even if shards are active
    #[prost(bool, tag="2")]
    pub force: bool,
    /// Graceful shutdown timeout
    #[prost(message, optional, tag="3")]
    pub shutdown_timeout: ::core::option::Option<::prost_types::Duration>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetGroupRequest {
    /// Group to retrieve
    #[prost(string, tag="1")]
    pub group_id: ::prost::alloc::string::String,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetGroupResponse {
    /// Actor group
    #[prost(message, optional, tag="1")]
    pub group: ::core::option::Option<ActorGroup>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListGroupsRequest {
    /// Filter by actor type (optional)
    #[prost(string, tag="1")]
    pub actor_type: ::prost::alloc::string::String,
    /// Filter by state (optional)
    #[prost(enumeration="GroupState", tag="2")]
    pub state: i32,
    /// Pagination
    #[prost(message, optional, tag="3")]
    pub page_request: ::core::option::Option<super::super::common::v1::PageRequest>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListGroupsResponse {
    /// Actor groups
    #[prost(message, repeated, tag="1")]
    pub groups: ::prost::alloc::vec::Vec<ActorGroup>,
    /// Pagination
    #[prost(message, optional, tag="2")]
    pub page_response: ::core::option::Option<super::super::common::v1::PageResponse>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScaleGroupRequest {
    /// Group to scale
    #[prost(string, tag="1")]
    pub group_id: ::prost::alloc::string::String,
    /// New shard count
    #[prost(uint32, tag="2")]
    pub new_shard_count: u32,
    /// Rebalancing policy
    #[prost(enumeration="super::super::actor::v1::RebalancePolicy", tag="3")]
    pub rebalance_policy: i32,
    /// Configuration for new shards (if scaling up)
    #[prost(message, optional, tag="4")]
    pub new_shard_config: ::core::option::Option<super::super::actor::v1::ActorConfig>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScaleGroupResponse {
    /// Updated actor group
    #[prost(message, optional, tag="1")]
    pub group: ::core::option::Option<ActorGroup>,
    /// Rebalancing status
    #[prost(message, optional, tag="2")]
    pub rebalance_status: ::core::option::Option<RebalanceStatus>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SendToShardRequest {
    /// Group to send to
    #[prost(string, tag="1")]
    pub group_id: ::prost::alloc::string::String,
    /// Partition key to determine target shard
    #[prost(bytes="vec", tag="2")]
    pub partition_key: ::prost::alloc::vec::Vec<u8>,
    /// Message to send
    #[prost(message, optional, tag="3")]
    pub message: ::core::option::Option<super::super::actor::v1::Message>,
    /// Wait for response
    #[prost(bool, tag="4")]
    pub wait_for_response: bool,
    /// Timeout for response
    #[prost(message, optional, tag="5")]
    pub timeout: ::core::option::Option<::prost_types::Duration>,
}
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SendToShardResponse {
    /// Shard that handled the message
    #[prost(uint32, tag="1")]
    pub shard_id: u32,
    /// Response from shard (if wait_for_response = true)
    #[prost(message, optional, tag="2")]
    pub response: ::core::option::Option<super::super::actor::v1::Message>,
}
/// Actor group state
#[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum GroupState {
    GroupStateUnspecified = 0,
    /// Shards being created
    GroupStateCreating = 1,
    /// All shards active
    GroupStateActive = 2,
    /// Shards being rebalanced
    GroupStateRebalancing = 3,
    /// Shards being drained
    GroupStateDraining = 4,
    /// All shards stopped
    GroupStateStopped = 5,
}
impl GroupState {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            GroupState::GroupStateUnspecified => "GROUP_STATE_UNSPECIFIED",
            GroupState::GroupStateCreating => "GROUP_STATE_CREATING",
            GroupState::GroupStateActive => "GROUP_STATE_ACTIVE",
            GroupState::GroupStateRebalancing => "GROUP_STATE_REBALANCING",
            GroupState::GroupStateDraining => "GROUP_STATE_DRAINING",
            GroupState::GroupStateStopped => "GROUP_STATE_STOPPED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "GROUP_STATE_UNSPECIFIED" => Some(Self::GroupStateUnspecified),
            "GROUP_STATE_CREATING" => Some(Self::GroupStateCreating),
            "GROUP_STATE_ACTIVE" => Some(Self::GroupStateActive),
            "GROUP_STATE_REBALANCING" => Some(Self::GroupStateRebalancing),
            "GROUP_STATE_DRAINING" => Some(Self::GroupStateDraining),
            "GROUP_STATE_STOPPED" => Some(Self::GroupStateStopped),
            _ => None,
        }
    }
}
/// Aggregation strategy for scatter-gather results
#[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum AggregationStrategy {
    AggregationStrategyUnspecified = 0,
    /// Concatenate all results
    AggregationStrategyConcat = 1,
    /// Merge using lattice (coordination-free)
    AggregationStrategyMerge = 2,
    /// Custom reduce function
    AggregationStrategyReduce = 3,
    /// Return first response only
    AggregationStrategyFirst = 4,
    /// Return majority value
    AggregationStrategyMajority = 5,
}
impl AggregationStrategy {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            AggregationStrategy::AggregationStrategyUnspecified => "AGGREGATION_STRATEGY_UNSPECIFIED",
            AggregationStrategy::AggregationStrategyConcat => "AGGREGATION_STRATEGY_CONCAT",
            AggregationStrategy::AggregationStrategyMerge => "AGGREGATION_STRATEGY_MERGE",
            AggregationStrategy::AggregationStrategyReduce => "AGGREGATION_STRATEGY_REDUCE",
            AggregationStrategy::AggregationStrategyFirst => "AGGREGATION_STRATEGY_FIRST",
            AggregationStrategy::AggregationStrategyMajority => "AGGREGATION_STRATEGY_MAJORITY",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "AGGREGATION_STRATEGY_UNSPECIFIED" => Some(Self::AggregationStrategyUnspecified),
            "AGGREGATION_STRATEGY_CONCAT" => Some(Self::AggregationStrategyConcat),
            "AGGREGATION_STRATEGY_MERGE" => Some(Self::AggregationStrategyMerge),
            "AGGREGATION_STRATEGY_REDUCE" => Some(Self::AggregationStrategyReduce),
            "AGGREGATION_STRATEGY_FIRST" => Some(Self::AggregationStrategyFirst),
            "AGGREGATION_STRATEGY_MAJORITY" => Some(Self::AggregationStrategyMajority),
            _ => None,
        }
    }
}
include!("plexspaces.actor_groups.v1.tonic.rs");
// @@protoc_insertion_point(module)