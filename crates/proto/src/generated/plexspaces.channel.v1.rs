// @generated
// This file is @generated by prost-build.
/// Channel configuration
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ChannelConfig {
    /// Unique channel name/topic
    #[prost(string, tag="1")]
    pub name: ::prost::alloc::string::String,
    /// Backend type (in-memory, Redis, Kafka)
    #[prost(enumeration="ChannelBackend", tag="2")]
    pub backend: i32,
    /// Capacity (0 = unbounded, >0 = bounded)
    /// - In-memory: buffer size
    /// - Redis: stream max length
    /// - Kafka: batch size hint
    #[prost(uint64, tag="3")]
    pub capacity: u64,
    /// Delivery guarantee
    #[prost(enumeration="DeliveryGuarantee", tag="4")]
    pub delivery: i32,
    /// Ordering guarantee
    #[prost(enumeration="OrderingGuarantee", tag="5")]
    pub ordering: i32,
    /// Optional: TTL for messages
    #[prost(message, optional, tag="20")]
    pub message_ttl: ::core::option::Option<::prost_types::Duration>,
    /// Optional: Dead-letter queue for failed messages
    #[prost(string, tag="21")]
    pub dead_letter_queue: ::prost::alloc::string::String,
    /// Maximum number of retries before sending to DLQ (default: 3)
    /// After N failures, message is sent to Dead Letter Queue instead of requeuing
    /// Set to 0 to disable retries (immediate DLQ on first failure)
    /// Only applies to channels that support ack/nack/dlq (Redis, Kafka, etc.)
    /// InMemory channels ignore this (no retry/DLQ support)
    #[prost(uint32, tag="22")]
    pub max_retries: u32,
    /// Enable Dead Letter Queue (DLQ) for failed messages (default: true)
    /// When enabled, messages that fail max_retries times are sent to DLQ
    /// When disabled, messages are dropped after max_retries failures
    /// Only applies to channels that support DLQ (Redis, Kafka, etc.)
    /// InMemory channels ignore this (no retry/DLQ support)
    #[prost(bool, tag="23")]
    pub dlq_enabled: bool,
    /// Backend-specific configuration
    #[prost(oneof="channel_config::BackendConfig", tags="10, 11, 12, 13, 14, 15, 16")]
    pub backend_config: ::core::option::Option<channel_config::BackendConfig>,
}
/// Nested message and enum types in `ChannelConfig`.
pub mod channel_config {
    /// Backend-specific configuration
    #[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum BackendConfig {
        #[prost(message, tag="10")]
        InMemory(super::InMemoryConfig),
        #[prost(message, tag="11")]
        Redis(super::RedisConfig),
        #[prost(message, tag="12")]
        Kafka(super::KafkaConfig),
        #[prost(message, tag="13")]
        Sqlite(super::SqliteConfig),
        #[prost(message, tag="14")]
        Nats(super::NatsConfig),
        #[prost(message, tag="15")]
        Udp(super::UdpConfig),
        #[prost(message, tag="16")]
        Sqs(super::SqsConfig),
    }
}
/// In-memory channel configuration
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct InMemoryConfig {
    #[prost(enumeration="in_memory_config::BackpressureStrategy", tag="1")]
    pub backpressure: i32,
    /// Timeout for blocking sends
    #[prost(message, optional, tag="2")]
    pub send_timeout: ::core::option::Option<::prost_types::Duration>,
    /// Timeout for blocking receives
    #[prost(message, optional, tag="3")]
    pub receive_timeout: ::core::option::Option<::prost_types::Duration>,
}
/// Nested message and enum types in `InMemoryConfig`.
pub mod in_memory_config {
    /// Backpressure strategy when channel is full
    #[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum BackpressureStrategy {
        /// Block sender until space available
        BackpressureStrategyBlock = 0,
        /// Drop oldest message
        BackpressureStrategyDropOldest = 1,
        /// Drop newest message (reject send)
        BackpressureStrategyDropNewest = 2,
        /// Return error to sender
        BackpressureStrategyError = 3,
    }
    impl BackpressureStrategy {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                BackpressureStrategy::BackpressureStrategyBlock => "BACKPRESSURE_STRATEGY_BLOCK",
                BackpressureStrategy::BackpressureStrategyDropOldest => "BACKPRESSURE_STRATEGY_DROP_OLDEST",
                BackpressureStrategy::BackpressureStrategyDropNewest => "BACKPRESSURE_STRATEGY_DROP_NEWEST",
                BackpressureStrategy::BackpressureStrategyError => "BACKPRESSURE_STRATEGY_ERROR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "BACKPRESSURE_STRATEGY_BLOCK" => Some(Self::BackpressureStrategyBlock),
                "BACKPRESSURE_STRATEGY_DROP_OLDEST" => Some(Self::BackpressureStrategyDropOldest),
                "BACKPRESSURE_STRATEGY_DROP_NEWEST" => Some(Self::BackpressureStrategyDropNewest),
                "BACKPRESSURE_STRATEGY_ERROR" => Some(Self::BackpressureStrategyError),
                _ => None,
            }
        }
    }
}
/// Redis Streams configuration
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RedisConfig {
    /// Redis connection URL
    #[prost(string, tag="1")]
    pub url: ::prost::alloc::string::String,
    /// Stream key (channel name in Redis)
    #[prost(string, tag="2")]
    pub stream_key: ::prost::alloc::string::String,
    /// Consumer group name (for load balancing)
    #[prost(string, tag="3")]
    pub consumer_group: ::prost::alloc::string::String,
    /// Consumer name (unique per worker)
    #[prost(string, tag="4")]
    pub consumer_name: ::prost::alloc::string::String,
    /// Maximum stream length (MAXLEN in Redis)
    #[prost(uint64, tag="5")]
    pub max_length: u64,
    /// Claim timeout for failed consumers
    #[prost(message, optional, tag="6")]
    pub claim_timeout: ::core::option::Option<::prost_types::Duration>,
    /// Connection pool size
    #[prost(uint32, tag="7")]
    pub pool_size: u32,
}
/// Kafka configuration
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct KafkaConfig {
    /// Kafka broker addresses
    #[prost(string, repeated, tag="1")]
    pub brokers: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Topic name
    #[prost(string, tag="2")]
    pub topic: ::prost::alloc::string::String,
    /// Consumer group ID
    #[prost(string, tag="3")]
    pub consumer_group: ::prost::alloc::string::String,
    /// Number of partitions (for topic creation)
    #[prost(uint32, tag="4")]
    pub partitions: u32,
    /// Replication factor
    #[prost(uint32, tag="5")]
    pub replication_factor: u32,
    #[prost(enumeration="kafka_config::CompressionType", tag="6")]
    pub compression: i32,
    #[prost(enumeration="kafka_config::ProducerAcks", tag="7")]
    pub acks: i32,
    /// Batch size for producers
    #[prost(uint64, tag="8")]
    pub batch_size: u64,
    /// Linger time for batching
    #[prost(message, optional, tag="9")]
    pub linger_ms: ::core::option::Option<::prost_types::Duration>,
}
/// Nested message and enum types in `KafkaConfig`.
pub mod kafka_config {
    /// Compression type
    #[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum CompressionType {
        CompressionTypeNone = 0,
        CompressionTypeGzip = 1,
        CompressionTypeSnappy = 2,
        CompressionTypeLz4 = 3,
        CompressionTypeZstd = 4,
    }
    impl CompressionType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                CompressionType::CompressionTypeNone => "COMPRESSION_TYPE_NONE",
                CompressionType::CompressionTypeGzip => "COMPRESSION_TYPE_GZIP",
                CompressionType::CompressionTypeSnappy => "COMPRESSION_TYPE_SNAPPY",
                CompressionType::CompressionTypeLz4 => "COMPRESSION_TYPE_LZ4",
                CompressionType::CompressionTypeZstd => "COMPRESSION_TYPE_ZSTD",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "COMPRESSION_TYPE_NONE" => Some(Self::CompressionTypeNone),
                "COMPRESSION_TYPE_GZIP" => Some(Self::CompressionTypeGzip),
                "COMPRESSION_TYPE_SNAPPY" => Some(Self::CompressionTypeSnappy),
                "COMPRESSION_TYPE_LZ4" => Some(Self::CompressionTypeLz4),
                "COMPRESSION_TYPE_ZSTD" => Some(Self::CompressionTypeZstd),
                _ => None,
            }
        }
    }
    /// Producer acks
    #[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum ProducerAcks {
        /// No acks (fastest, least reliable)
        ProducerAcksNone = 0,
        /// Leader ack only
        ProducerAcksLeader = 1,
        /// All replicas ack
        ProducerAcksAll = 2,
    }
    impl ProducerAcks {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                ProducerAcks::ProducerAcksNone => "PRODUCER_ACKS_NONE",
                ProducerAcks::ProducerAcksLeader => "PRODUCER_ACKS_LEADER",
                ProducerAcks::ProducerAcksAll => "PRODUCER_ACKS_ALL",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "PRODUCER_ACKS_NONE" => Some(Self::ProducerAcksNone),
                "PRODUCER_ACKS_LEADER" => Some(Self::ProducerAcksLeader),
                "PRODUCER_ACKS_ALL" => Some(Self::ProducerAcksAll),
                _ => None,
            }
        }
    }
}
/// SQLite configuration (for testing and single-node durability)
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SqliteConfig {
    /// SQLite database path (":memory:" for in-memory, file path for persistent)
    #[prost(string, tag="1")]
    pub database_path: ::prost::alloc::string::String,
    /// Table name for storing messages (default: "channel_messages")
    #[prost(string, tag="2")]
    pub table_name: ::prost::alloc::string::String,
    /// Enable WAL mode for better concurrency (default: true)
    #[prost(bool, tag="3")]
    pub wal_mode: bool,
    /// Cleanup old messages after ack (default: true)
    #[prost(bool, tag="4")]
    pub cleanup_acked: bool,
    /// Maximum age for acked messages before cleanup (in seconds, 0 = no cleanup)
    #[prost(uint64, tag="5")]
    pub cleanup_age_seconds: u64,
}
/// NATS configuration (for lightweight distributed messaging)
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NatsConfig {
    /// NATS server URLs (comma-separated for clustering)
    /// Example: "nats://localhost:4222,nats://localhost:4223"
    #[prost(string, tag="1")]
    pub servers: ::prost::alloc::string::String,
    /// Subject/topic name (default: channel name)
    #[prost(string, tag="2")]
    pub subject: ::prost::alloc::string::String,
    /// Queue group for load-balanced consumption (optional)
    /// - If set, messages are distributed across consumers in the group
    /// - If empty, all subscribers receive all messages (pub/sub)
    #[prost(string, tag="3")]
    pub queue_group: ::prost::alloc::string::String,
    /// Enable JetStream for persistence (default: false)
    /// - Requires NATS server with JetStream enabled
    /// - Provides at-least-once delivery guarantees
    #[prost(bool, tag="4")]
    pub jetstream_enabled: bool,
    /// JetStream stream name (default: channel name)
    #[prost(string, tag="5")]
    pub jetstream_stream: ::prost::alloc::string::String,
    /// JetStream consumer name (default: queue_group or channel name)
    #[prost(string, tag="6")]
    pub jetstream_consumer: ::prost::alloc::string::String,
    /// Connection timeout (default: 5 seconds)
    #[prost(message, optional, tag="7")]
    pub connect_timeout: ::core::option::Option<::prost_types::Duration>,
    /// Reconnect attempts (default: 10, -1 for unlimited)
    #[prost(int32, tag="8")]
    pub reconnect_attempts: i32,
    /// Enable TLS (default: false)
    #[prost(bool, tag="9")]
    pub tls_enabled: bool,
    /// TLS certificate path (optional)
    #[prost(string, tag="10")]
    pub tls_cert_path: ::prost::alloc::string::String,
    /// TLS key path (optional)
    #[prost(string, tag="11")]
    pub tls_key_path: ::prost::alloc::string::String,
    /// TLS CA certificate path (optional)
    #[prost(string, tag="12")]
    pub tls_ca_path: ::prost::alloc::string::String,
}
/// UDP configuration (for multicast pub/sub within a cluster)
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UdpConfig {
    /// Multicast address for pub/sub (default: "239.255.0.1")
    /// - Must be in multicast range (224.0.0.0 to 239.255.255.255)
    /// - All nodes in cluster must use same multicast address
    #[prost(string, tag="1")]
    pub multicast_address: ::prost::alloc::string::String,
    /// Multicast port (default: 9999)
    /// - All nodes in cluster must use same port
    #[prost(uint32, tag="2")]
    pub multicast_port: u32,
    /// Local bind address (default: "0.0.0.0")
    #[prost(string, tag="3")]
    pub bind_address: ::prost::alloc::string::String,
    /// TTL for messages (default: 60 seconds)
    #[prost(uint32, tag="4")]
    pub message_ttl_seconds: u32,
}
/// AWS SQS configuration
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SqsConfig {
    /// AWS region (e.g., "us-east-1")
    #[prost(string, tag="1")]
    pub region: ::prost::alloc::string::String,
    /// Queue name prefix (default: "plexspaces-")
    /// Actual queue names will be: {prefix}{channel_name}
    #[prost(string, tag="2")]
    pub queue_prefix: ::prost::alloc::string::String,
    /// Endpoint URL (for local testing with SQS Local)
    /// Leave empty for production (uses AWS service)
    #[prost(string, tag="3")]
    pub endpoint_url: ::prost::alloc::string::String,
    /// Visibility timeout in seconds (default: 30)
    /// How long a message is invisible after being received
    #[prost(uint32, tag="4")]
    pub visibility_timeout_seconds: u32,
    /// Message retention period in seconds (default: 345600 = 4 days)
    #[prost(uint32, tag="5")]
    pub message_retention_period_seconds: u32,
    /// Dead Letter Queue configuration
    #[prost(bool, tag="6")]
    pub dlq_enabled: bool,
    /// Max receive count before sending to DLQ (default: 3)
    #[prost(uint32, tag="7")]
    pub dlq_max_receive_count: u32,
    /// Receive message wait time in seconds (long polling, default: 20)
    /// 0 = short polling, >0 = long polling
    #[prost(uint32, tag="8")]
    pub receive_message_wait_time_seconds: u32,
}
/// Channel message envelope
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ChannelMessage {
    /// Unique message ID (ULID)
    #[prost(string, tag="1")]
    pub id: ::prost::alloc::string::String,
    /// Channel name/topic
    #[prost(string, tag="2")]
    pub channel: ::prost::alloc::string::String,
    /// Sender actor ID (optional)
    #[prost(string, tag="3")]
    pub sender_id: ::prost::alloc::string::String,
    /// Message payload (opaque bytes)
    #[prost(bytes="vec", tag="4")]
    pub payload: ::prost::alloc::vec::Vec<u8>,
    /// Message headers (metadata)
    #[prost(map="string, string", tag="5")]
    pub headers: ::std::collections::HashMap<::prost::alloc::string::String, ::prost::alloc::string::String>,
    /// Message timestamp
    #[prost(message, optional, tag="6")]
    pub timestamp: ::core::option::Option<::prost_types::Timestamp>,
    /// Partition key (for Kafka/Redis)
    #[prost(string, tag="7")]
    pub partition_key: ::prost::alloc::string::String,
    /// Correlation ID (for request/reply)
    #[prost(string, tag="8")]
    pub correlation_id: ::prost::alloc::string::String,
    /// Reply-to channel (for RPC pattern)
    #[prost(string, tag="9")]
    pub reply_to: ::prost::alloc::string::String,
    /// Delivery count (for retry tracking)
    #[prost(uint32, tag="10")]
    pub delivery_count: u32,
}
/// Channel statistics
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ChannelStats {
    /// Channel name
    #[prost(string, tag="1")]
    pub name: ::prost::alloc::string::String,
    /// Backend type
    #[prost(enumeration="ChannelBackend", tag="2")]
    pub backend: i32,
    /// Total messages sent
    #[prost(uint64, tag="3")]
    pub messages_sent: u64,
    /// Total messages received
    #[prost(uint64, tag="4")]
    pub messages_received: u64,
    /// Messages pending (in queue)
    #[prost(uint64, tag="5")]
    pub messages_pending: u64,
    /// Messages failed
    #[prost(uint64, tag="6")]
    pub messages_failed: u64,
    /// Average latency (microseconds)
    #[prost(uint64, tag="7")]
    pub avg_latency_us: u64,
    /// Current throughput (messages/second)
    #[prost(double, tag="8")]
    pub throughput: f64,
    /// Backend-specific stats
    #[prost(map="string, string", tag="9")]
    pub backend_stats: ::std::collections::HashMap<::prost::alloc::string::String, ::prost::alloc::string::String>,
}
/// CreateChannel request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CreateChannelRequest {
    #[prost(message, optional, tag="1")]
    pub config: ::core::option::Option<ChannelConfig>,
}
/// CreateChannel response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CreateChannelResponse {
    #[prost(string, tag="1")]
    pub channel_id: ::prost::alloc::string::String,
}
/// Send request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SendRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
    #[prost(message, optional, tag="2")]
    pub message: ::core::option::Option<ChannelMessage>,
    #[prost(message, optional, tag="3")]
    pub timeout: ::core::option::Option<::prost_types::Duration>,
}
/// Send response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SendResponse {
    #[prost(string, tag="1")]
    pub message_id: ::prost::alloc::string::String,
    #[prost(bool, tag="2")]
    pub sent: bool,
}
/// Receive request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ReceiveRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
    #[prost(message, optional, tag="2")]
    pub timeout: ::core::option::Option<::prost_types::Duration>,
    /// For batch receives
    #[prost(uint32, tag="3")]
    pub max_messages: u32,
}
/// Receive response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ReceiveResponse {
    #[prost(message, repeated, tag="1")]
    pub messages: ::prost::alloc::vec::Vec<ChannelMessage>,
}
/// Subscribe request (streaming)
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SubscribeRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
    /// For load-balanced consumption
    #[prost(string, tag="2")]
    pub consumer_group: ::prost::alloc::string::String,
    /// Header-based filtering
    #[prost(map="string, string", tag="3")]
    pub filters: ::std::collections::HashMap<::prost::alloc::string::String, ::prost::alloc::string::String>,
}
/// Publish request (pub/sub)
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PublishRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
    #[prost(message, optional, tag="2")]
    pub message: ::core::option::Option<ChannelMessage>,
}
/// Publish response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PublishResponse {
    #[prost(string, tag="1")]
    pub message_id: ::prost::alloc::string::String,
    #[prost(uint32, tag="2")]
    pub subscriber_count: u32,
}
/// Ack request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AckRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
    #[prost(string, tag="2")]
    pub message_id: ::prost::alloc::string::String,
}
/// Ack response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AckResponse {
    #[prost(bool, tag="1")]
    pub acknowledged: bool,
}
/// Nack request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NackRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
    #[prost(string, tag="2")]
    pub message_id: ::prost::alloc::string::String,
    #[prost(bool, tag="3")]
    pub requeue: bool,
}
/// Nack response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct NackResponse {
    #[prost(bool, tag="1")]
    pub requeued: bool,
}
/// GetStats request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetStatsRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
}
/// GetStats response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetStatsResponse {
    #[prost(message, optional, tag="1")]
    pub stats: ::core::option::Option<ChannelStats>,
}
/// DeleteChannel request
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DeleteChannelRequest {
    #[prost(string, tag="1")]
    pub channel: ::prost::alloc::string::String,
}
/// DeleteChannel response
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DeleteChannelResponse {
    #[prost(bool, tag="1")]
    pub deleted: bool,
}
/// Channel backend type determines the underlying transport
#[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ChannelBackend {
    /// In-process multi-producer single-consumer channel (Go-like)
    /// - Fastest for same-node communication
    /// - No persistence, lost on crash
    /// - Bounded or unbounded capacity
    ChannelBackendInMemory = 0,
    /// Redis Streams for distributed messaging
    /// - Persistent, survives crashes
    /// - Consumer groups for load balancing
    /// - Cross-node communication
    ChannelBackendRedis = 1,
    /// Kafka for high-throughput distributed streaming
    /// - Durable, partitioned, replicated
    /// - Horizontal scalability
    /// - Cross-node, cross-datacenter
    ChannelBackendKafka = 2,
    /// SQLite for testing and single-node durability
    /// - Persistent, survives crashes
    /// - Good for testing recovery scenarios
    /// - Single-node only (not distributed)
    ChannelBackendSqlite = 3,
    /// NATS for lightweight distributed messaging
    /// - High performance, low latency
    /// - Pub/sub and request/reply patterns
    /// - JetStream for persistence (optional)
    /// - Cross-node, cross-datacenter
    ChannelBackendNats = 4,
    /// UDP multicast for lightweight pub/sub within a cluster
    /// - Very low latency, high throughput
    /// - Multicast pub/sub for cluster-wide messaging
    /// - Unicast point-to-point messaging
    /// - No persistence, best-effort delivery
    /// - Requires nodes to share same cluster_name
    ChannelBackendUdp = 5,
    /// AWS SQS for managed message queuing
    /// - Fully managed, serverless
    /// - Dead Letter Queue (DLQ) support
    /// - At-least-once delivery with visibility timeout
    /// - Auto-scaling, no infrastructure management
    ChannelBackendSqs = 6,
    /// Custom backend (user-provided implementation)
    ChannelBackendCustom = 99,
}
impl ChannelBackend {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            ChannelBackend::ChannelBackendInMemory => "CHANNEL_BACKEND_IN_MEMORY",
            ChannelBackend::ChannelBackendRedis => "CHANNEL_BACKEND_REDIS",
            ChannelBackend::ChannelBackendKafka => "CHANNEL_BACKEND_KAFKA",
            ChannelBackend::ChannelBackendSqlite => "CHANNEL_BACKEND_SQLITE",
            ChannelBackend::ChannelBackendNats => "CHANNEL_BACKEND_NATS",
            ChannelBackend::ChannelBackendUdp => "CHANNEL_BACKEND_UDP",
            ChannelBackend::ChannelBackendSqs => "CHANNEL_BACKEND_SQS",
            ChannelBackend::ChannelBackendCustom => "CHANNEL_BACKEND_CUSTOM",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "CHANNEL_BACKEND_IN_MEMORY" => Some(Self::ChannelBackendInMemory),
            "CHANNEL_BACKEND_REDIS" => Some(Self::ChannelBackendRedis),
            "CHANNEL_BACKEND_KAFKA" => Some(Self::ChannelBackendKafka),
            "CHANNEL_BACKEND_SQLITE" => Some(Self::ChannelBackendSqlite),
            "CHANNEL_BACKEND_NATS" => Some(Self::ChannelBackendNats),
            "CHANNEL_BACKEND_UDP" => Some(Self::ChannelBackendUdp),
            "CHANNEL_BACKEND_SQS" => Some(Self::ChannelBackendSqs),
            "CHANNEL_BACKEND_CUSTOM" => Some(Self::ChannelBackendCustom),
            _ => None,
        }
    }
}
/// Channel delivery semantics
#[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum DeliveryGuarantee {
    /// At-most-once: Fire and forget, may lose messages
    DeliveryGuaranteeAtMostOnce = 0,
    /// At-least-once: Retries until acknowledged, may duplicate
    DeliveryGuaranteeAtLeastOnce = 1,
    /// Exactly-once: Deduplication, no retries needed (Kafka only)
    DeliveryGuaranteeExactlyOnce = 2,
}
impl DeliveryGuarantee {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            DeliveryGuarantee::DeliveryGuaranteeAtMostOnce => "DELIVERY_GUARANTEE_AT_MOST_ONCE",
            DeliveryGuarantee::DeliveryGuaranteeAtLeastOnce => "DELIVERY_GUARANTEE_AT_LEAST_ONCE",
            DeliveryGuarantee::DeliveryGuaranteeExactlyOnce => "DELIVERY_GUARANTEE_EXACTLY_ONCE",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "DELIVERY_GUARANTEE_AT_MOST_ONCE" => Some(Self::DeliveryGuaranteeAtMostOnce),
            "DELIVERY_GUARANTEE_AT_LEAST_ONCE" => Some(Self::DeliveryGuaranteeAtLeastOnce),
            "DELIVERY_GUARANTEE_EXACTLY_ONCE" => Some(Self::DeliveryGuaranteeExactlyOnce),
            _ => None,
        }
    }
}
/// Channel ordering guarantee
#[derive(Clone, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum OrderingGuarantee {
    /// No ordering guarantee (fastest)
    OrderingGuaranteeNone = 0,
    /// FIFO per producer
    OrderingGuaranteeFifo = 1,
    /// Total order across all producers (Kafka partition)
    OrderingGuaranteeTotal = 2,
}
impl OrderingGuarantee {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            OrderingGuarantee::OrderingGuaranteeNone => "ORDERING_GUARANTEE_NONE",
            OrderingGuarantee::OrderingGuaranteeFifo => "ORDERING_GUARANTEE_FIFO",
            OrderingGuarantee::OrderingGuaranteeTotal => "ORDERING_GUARANTEE_TOTAL",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "ORDERING_GUARANTEE_NONE" => Some(Self::OrderingGuaranteeNone),
            "ORDERING_GUARANTEE_FIFO" => Some(Self::OrderingGuaranteeFifo),
            "ORDERING_GUARANTEE_TOTAL" => Some(Self::OrderingGuaranteeTotal),
            _ => None,
        }
    }
}
include!("plexspaces.channel.v1.tonic.rs");
// @@protoc_insertion_point(module)